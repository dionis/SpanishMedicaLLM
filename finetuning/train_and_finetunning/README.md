## For train and evaluation

**Resources**
Files:
  - hackaton2024_entrenamiento_llm_instrucciones.ipynb

  - hackaton2024_fine_tune_gemma_2b_on_openhermes_using_qlora.ipynb

Source code in jupyter nootebook 


Was used the conference on SomosNLP Hackaton 2024
 
  - [https://github.com/somosnlp/recursos/blob/main/hackathon_2024/fine_tune_gemma_2b_on_openhermes_using_qlora.ipynb](https://github.com/somosnlp/recursos/blob/main/hackathon_2024/entrenamiento_llm_instrucciones.ipynb)


  **[Taller + AMA: Entrenamiento de LLMs, Alejandro Vaca @LenguajeNaturalAI](https://www.youtube.com/watch?v=458UWBlBdtI&t=3373s)**

  - [Fine-tune GEMMA 2B on OpenHermes using QLoRA](https://github.com/somosnlp/recursos/blob/main/hackathon_2024/fine_tune_gemma_2b_on_openhermes_using_qlora.ipynb)


 **Build sintetic datasets**

 -[Argilla y distilabel, herramientas para crear modelos como Notus, Gabriel @Argilla](https://www.youtube.com/watch?v=riM3pgV4m_I&t=2260s)


**Code Source**

- [Muy IMPORTANTE](https://github.com/somosnlp/recursos/blob/main/hackathon_2024/creacion_de_datasets_sinteticos_con_distilabel.ipynb)

- [Argilla y distilabel, herramientas para crear modelos como Notus](https://github.com/somosnlp/recursos/blob/main/hackathon_2024/taller_distilabel_y_argilla.ipynb)

